# -*- coding: utf-8 -*-
"""Brain Tumor Detection using CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15Vi0fFxNA4Eny2hWjwKrkvwTnuldfa0V
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

from google.colab import drive
drive.mount('/content/drive')

data_path = '/content/drive/My Drive/brain_tumor_dataset'

import os
print(os.listdir(data_path))

categories = ['yes', 'no']
data = []
labels = []

# Load and preprocess images
for category in categories:
    folder_path = os.path.join(data_path, category)
    label = categories.index(category)
    for img_name in os.listdir(folder_path):
        img_path = os.path.join(folder_path, img_name)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # grayscale
        img = cv2.resize(img, (128, 128))  # Resize
        data.append(img)
        labels.append(label)

# Convert to NumPy array
data = np.array(data)
labels = np.array(labels)

# Normalize and reshape data
data = data / 255.0
data = data.reshape(-1, 128, 128, 1)

# One-hot encode labels
labels = to_categorical(labels, num_classes=2)

# Train/test split
x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)

# CNN Model
model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))  # prevent overfitting
model.add(Dense(2, activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), batch_size=16)

# Evaluate
loss, acc = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {acc*100:.2f}%")

#Visualization (Accuracy/Loss Graph)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

#Test Prediction
# Predict on one image
img = cv2.imread('/content/drive/MyDrive/brain_tumor_dataset/yes/Y1.jpg', cv2.IMREAD_GRAYSCALE)
img = cv2.resize(img, (128, 128))
img = img / 255.0
img = img.reshape(1, 128, 128, 1)

prediction = model.predict(img)
print("Prediction:", prediction)
print("Tumor" if np.argmax(prediction) == 0 else "No Tumor")